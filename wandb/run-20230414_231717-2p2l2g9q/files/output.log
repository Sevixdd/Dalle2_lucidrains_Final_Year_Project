100% 1/1 [00:00<00:00, 2989.53it/s]
Traceback (most recent call last):
  File "/home/sevi/Documents/GitHub/FYP/train_prior.py", line 771, in <module>
    main()
  File "/home/sevi/anaconda3/envs/AdvAI/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/home/sevi/anaconda3/envs/AdvAI/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/home/sevi/anaconda3/envs/AdvAI/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/sevi/anaconda3/envs/AdvAI/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "/home/sevi/Documents/GitHub/FYP/train_prior.py", line 767, in main
    initialize_training(config_file, accelerator)
  File "/home/sevi/Documents/GitHub/FYP/train_prior.py", line 750, in initialize_training
    train(
  File "/home/sevi/Documents/GitHub/FYP/train_prior.py", line 475, in train
    loss = trainer(text=txt, image_embed=img)
  File "/home/sevi/anaconda3/envs/AdvAI/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/sevi/anaconda3/envs/AdvAI/lib/python3.8/site-packages/dalle2_pytorch/trainer.py", line 107, in inner
    out = fn(model, *args, **kwargs)
  File "/home/sevi/anaconda3/envs/AdvAI/lib/python3.8/site-packages/dalle2_pytorch/trainer.py", line 405, in forward
    loss = self.diffusion_prior(*chunked_args, **chunked_kwargs)
  File "/home/sevi/anaconda3/envs/AdvAI/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/sevi/anaconda3/envs/AdvAI/lib/python3.8/site-packages/dalle2_pytorch/dalle2_pytorch.py", line 1495, in forward
    return self.p_losses(image_embed, times, text_cond = text_cond, *args, **kwargs)
  File "/home/sevi/anaconda3/envs/AdvAI/lib/python3.8/site-packages/dalle2_pytorch/dalle2_pytorch.py", line 1380, in p_losses
    pred = self.net(
  File "/home/sevi/anaconda3/envs/AdvAI/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/sevi/anaconda3/envs/AdvAI/lib/python3.8/site-packages/dalle2_pytorch/dalle2_pytorch.py", line 1139, in forward
    tokens = self.causal_transformer(tokens)
  File "/home/sevi/anaconda3/envs/AdvAI/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/sevi/anaconda3/envs/AdvAI/lib/python3.8/site-packages/dalle2_pytorch/dalle2_pytorch.py", line 960, in forward
    x = attn(x, attn_bias = attn_bias) + x
  File "/home/sevi/anaconda3/envs/AdvAI/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/sevi/anaconda3/envs/AdvAI/lib/python3.8/site-packages/dalle2_pytorch/dalle2_pytorch.py", line 916, in forward
    return self.to_out(out)
  File "/home/sevi/anaconda3/envs/AdvAI/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/sevi/anaconda3/envs/AdvAI/lib/python3.8/site-packages/torch/nn/modules/container.py", line 139, in forward
    input = module(input)
  File "/home/sevi/anaconda3/envs/AdvAI/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/sevi/anaconda3/envs/AdvAI/lib/python3.8/site-packages/dalle2_pytorch/dalle2_pytorch.py", line 690, in forward
    return (x - mean) * (var + eps).rsqrt() * self.g
RuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 11.76 GiB total capacity; 9.48 GiB already allocated; 44.56 MiB free; 9.89 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Logging to wandb run sevixdd/prior_debugging/2p2l2g9q-giddy-bee-25
Saving checkpoint locally
[34m[5mGrabbing data...
[33mBeginning Prior Training : Distributed=False
{'tracking/epoch': 0}
{'tracking/samples-sec': tensor(53.6259, device='cuda:0'), 'tracking/samples-seen': tensor(45, device='cuda:0'), 'tracking/ema-decay': 0.0, 'tracking/training-l2': tensor(1.3535, device='cuda:0')}